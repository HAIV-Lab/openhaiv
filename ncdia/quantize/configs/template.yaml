model:
  name: 'resnet18'              # model name
  pretrained: True              # whether to use pretrained model

runner:
  name: 'ptq'                   # runner name

quantization:
  # Define the official torch.nn module with 'nn_{name}', e.g. 'nn_linear', 'nn_conv2d', etc.
  # Can match module names with regular expressions, e.g. 'nn_. *conv.*' matches all convolutional layers.
  # Can match module according its path in the model, e.g. '/layer1/.*/conv1' matches all conv1 in layer1.
  # It is possible to define each module repeatedly, with later definitions overwriting earlier ones.
  default:                      # default setting for all layers
    weight:                     # weight setting
      n_bits: 8                 # number of bits
      symmetric: True           # whether to use symmetric quantization
      signed: True              # whether to use signed quantization
      granularity: 'channel'    # quantization granularity
    activation:                 # activation setting
      n_bits: 8                 # number of bits
      symmetric: True           # whether to use symmetric quantization
      signed: True              # whether to use signed quantization
      granularity: 'channel'    # quantization granularity
    bn_folding: True            # whether to fold batch normalization into convolutional layers
    bias_correct:               # bias correction setting
      momentum: 0.1             # momentum for moving average

  nn_linear:                    # torch.nn.Linear
    weight:                     # weight setting
      n_bits: 8                 # number of bits
      symmetric: True           # whether to use symmetric quantization
      signed: True              # whether to use signed quantization
      granularity: 'channel'    # quantization granularity
    activation:                 # activation setting
      n_bits: 8                 # number of bits
      symmetric: True           # whether to use symmetric quantization
      signed: True              # whether to use signed quantization
      granularity: 'channel'    # quantization granularity
